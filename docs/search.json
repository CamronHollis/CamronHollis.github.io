[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CHollis Website Project",
    "section": "",
    "text": "This website was made to satisfy the requirements of the Fall 2023 Data Visualization class.\nNot all webpages have been recently rendered with updated menus, so if you can not find a page please return to this index homepage to navigate to more recent pages."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "I am Camron Hollis, currently of the PPPE PhD program at the University of Texas at Dallas.\n\nProfessional\nMy academic interests are international relations, political economy, and Marxian historiography. I am a student and teaching assistant at UT Dallas.\nFor academic inquiries: camron.hollis@utdallas.edu\n\n\nPersonal\nI sail, hike, and argue with people online.\nFor personal inquiries: camronjh@bellsouth.net\nBack to Home"
  },
  {
    "objectID": "EPPS5356.html",
    "href": "EPPS5356.html",
    "title": "EPPS 5356",
    "section": "",
    "text": "This page is for submissions for the EPPS 5356 Data Visualization.\nAssignment 1"
  },
  {
    "objectID": "EPPS5356Assignment1.html",
    "href": "EPPS5356Assignment1.html",
    "title": "EPPS 5356 Assignment 1",
    "section": "",
    "text": "Assignment 1\n\nAnscombe.R\n\n\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n\n\n\n\n\nGenerative Art Review\nFall.R\n\n\n\nLoading required package: proto\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\n\n\nChart critique\n\n\n\n\nFlorida Gun Death chart"
  },
  {
    "objectID": "EPPS6356Assignment1.html",
    "href": "EPPS6356Assignment1.html",
    "title": "EPPS 6356 Assignment 1",
    "section": "",
    "text": "1. Anscombe.R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Generative Art Review\nThis generative art is produced by Adobe using a ‘Generative Fill’ tool. The tool was used on famous album covers, generating images beyond the previous borders of the covers, to produce the below results.\n\n\n\n\n\n\n\n\n\n\n\nRespectfully, it does a bad job. The generative art muddies the artistic choices made on the album covers and makes goofy additions. The generative tool is not purposeful nor subtle, and simply creates vaguely related scenes to fill out as much space as the user commands.\n\n\n3. Fall.R\n\n\n\n\n\nThe leaf color is ‘darksalmon’, which is how I like my salmon.\n\n\n4. Chart critique\n\nThis is the Florida gun death chart, created by Reuters. This chart was criticized on its publication in 2014 for confusing people by having the line going down when it was really depicting an increase in gun deaths: At first glance, one might take away that gun murders had gone down in Florida after the passage of the Stand Your Ground law, while in fact the opposite is true. The creators of the graph defended themselves by claiming it was stylized after dripping blood, evocative of the deaths caused by gun violence. If that was their aim, they didn’t really commit. For example, if they made upside down bars instead of a line, it would have looked better.\nThe dripping blood aesthetic is not the only criticism of that can be made of the graph. The time axis is badly depicted, where it is harder to tell which dot is attached to which year, besides from the clearly labeled 2005. It is also not clear why the first and last point has a labeled death value, but no other point. The range of values is also much more narrow than the chart because the authors decided to include 0 and 1000, a choice I assume was to expand the amount of red headroom for their blood aesthetic.\nThe font and color choices are fine, although the big block of red makes the chart hart to look at for long period."
  },
  {
    "objectID": "EPPS6356Assignment1.html#assignment-1",
    "href": "EPPS6356Assignment1.html#assignment-1",
    "title": "EPPS 6356 Assignment 1",
    "section": "",
    "text": "This generative art is produced by Adobe using a ‘Generative Fill’ tool. The tool was used on famous album covers, generating images beyond the previous borders of the covers, to produce the below results.\n\n\n\n\n\n\n\n\n\n\n\nRespectfully, it does a bad job. The generative art muddies the artistic choices made on the album covers and makes goofy additions. The generative tool is not purposeful nor subtle, and simply creates vaguely related scenes to fill out as much space as the user commands.\n\n\n\n\n\n\n\n\nThe leaf color is ‘darksalmon’, which is how I like my salmon.\n\n\n\n\nThis is the Florida gun death chart, created by Reuters. This chart was criticized on its publication in 2014 for confusing people by having the line going down when it was really depicting an increase in gun deaths: At first glance, one might take away that gun murders had gone down in Florida after the passage of the Stand Your Ground law, while in fact the opposite is true. The creators of the graph defended themselves by claiming it was stylized after dripping blood, evocative of the deaths caused by gun violence. If that was their aim, they didn’t really commit. For example, if they made upside down bars instead of a line, it would have looked better.\nThe dripping blood aesthetic is not the only criticism of that can be made of the graph. The time axis is badly depicted, where it is harder to tell which dot is attached to which year, besides from the clearly labeled 2005. It is also not clear why the first and last point has a labeled death value, but no other point. The range of values is also much more narrow than the chart because the authors decided to include 0 and 1000, a choice I assume was to expand the amount of red headroom for their blood aesthetic.\nThe font and color choices are fine, although the big block of red makes the chart hart to look at for long period."
  },
  {
    "objectID": "EPPS6356Assignment2.html",
    "href": "EPPS6356Assignment2.html",
    "title": "EPPS 6356 Assignment 2",
    "section": "",
    "text": "1. murrell.R\n\n\n\n\n\n\n\n\n\n\n2. Using the World Wellbeing data\nData is taken from https://happyplanetindex.org/, utilizing table 2 covering all variables."
  },
  {
    "objectID": "EPPS6356Assignment2.html#assignment-2",
    "href": "EPPS6356Assignment2.html#assignment-2",
    "title": "EPPS 6356 Assignment 2",
    "section": "",
    "text": "Warning in xy.coords(x, y, xlabel, ylabel, log): NAs introduced by coercion"
  },
  {
    "objectID": "EPPS6356Assignment3.html",
    "href": "EPPS6356Assignment3.html",
    "title": "EPPS 6356 Assignment 3",
    "section": "",
    "text": "1. anscombe.r\nHere are all the plotted regressions from anscombe.r together.\n\n\n\n\n\n\n\n2. Finetuning\nEach plot has different fonts. They are TMS, Mono, Serif, and Sans respectively.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. ggplot2\nNow created in ggplot2, with different fonts, shapes, and sizes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Pre-Hackathon\nThe below figure is created in base r graphics\n\n\n\n\n\nThe below figure is created with ggplot2."
  },
  {
    "objectID": "EPPS6356Assignment4.html",
    "href": "EPPS6356Assignment4.html",
    "title": "EPPS 6356 Assignment 4",
    "section": "",
    "text": "library(ggplot2)\nknitr::opts_chunk$set(echo = TRUE)\n\n\nChart 1: Variable Width Column Chart\n\nowidall = read.csv(\"http://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data.csv?raw=true\")\nowidall = owidall[!grepl(\"^OWID\", owidall$iso_code), ]\nowideu = subset(owidall, continent==\"Europe\")\nowidnewyear = subset(owidall, date == \"2023-01-01\")\n\n\nowidnewyear2 = subset(owidnewyear, continent == \n  \"Europe\")\nowidnewyear2 = subset(owidnewyear2, location != \n  \"Gibraltar\")\n\n\n#plot(x = owidnewyear$population_density,y = owidnewyear$total_cases)\n\nw = owidnewyear2$population_density\npos &lt;- 0.5 * (cumsum(w) + cumsum(c(0, w[-length(w)])))\n\nggplot(data = owidnewyear2,\n       aes(x = pos,\n                 y = log(total_cases),\n                 width = w,\n                  fill = location)\n                 ) +\n    geom_col(aes(x = pos,\n                 y = log(total_cases),\n                 width = w,\n                  fill = location),\n                color = \"black\"\n                 ) +\n    geom_text(aes(label = location ), vjust = 5, size = 2.5, \n    nudge_x = 0.5, nudge_y = 0.5, \n    check_overlap = T,\n    color = \"white\") +\n    theme(legend.position=\"none\",\n      axis.ticks.x=element_blank(),\n      axis.text.x=element_text(size=1),\n      panel.background = element_rect(fill = 'grey50', color = 'black', size = 2),\n          panel.grid.major = element_line(color = 'black'),\n          panel.grid.minor = element_line(color = 'grey50', size = 2)\n      \n      \n      ) +\n    scale_x_continuous(labels = owidnewyear2$location, breaks = pos) +\n    labs(\n      title = \"The First 17 Countries in Europe: Total Covid cases, population density\",\n      x = \"Country; Bar width is relative population density\",\n      y = \"Total cases as of Jan 1st, 2023 (log)\"\n    )\n\n\n\n\n\n\nChart 2: Table with Embedded Charts\n\n  par(mfrow=c(2, 3) )\n\n  plot(\n  diff(ts(\n    subset(owidall, location == \"Albania\")$new_deaths )\n  ),\n  main = \"Deaths in Albania from Covid\",\n  col = \"grey40\",\n  xlab = \"Days from Jan 1, 2020\",\n  ylab = \"Difference in Deaths from Previous day\"\n  )\n  barplot(\n    owideu[1:1000,9],\n    col = \"darksalmon\",\n    main = \"Deaths in Albania from Covid\",\n    xlab = \"Days from Jan 1, 2020\",\n    ylab = \"Deaths\"\n  )\n  plot(\n    x = log(owideu$new_cases),\n    y = log(owideu$new_deaths),\n    font = 1, pch = 20, cex = 0.1,\n    col = \"gold4\",\n    main = \"Cases vs Deaths\",\n    xlab = \"New Cases (log)\",\n    ylab = \"New Deaths (log)\"\n  )\n  plot(\n  ts(\n    (log(\n    subset(owidall, location == \"China\")$new_cases )\n  )  ),\n  col = \"red4\",\n  main = \"New Cases in China\",\n    xlab = \"Days from Jan 1, 2020\",\n    ylab = \"New Cases (log)\"\n  )\n  \n  hist(\n    subset(owidall, date == \"2022-01-01\")$total_vaccinations_per_hundred,\n    breaks = 30,\n    xlim = c(0,300),\n    ylim = c(0, 10),\n    col = \"dodgerblue3\",\n    main = \"Total Vaccinations by Country\",\n    xlab = \"Total Vaccinations\",\n    ylab = \"Frequency by Country\"\n  )\n  plot(\n    ts(\n      subset(owidall, location == \"Iran\")$new_deaths),\n     lty=\"solid\", col = \"red3\",\n    main = \"Covid Deaths in Iran and Afghanistan\",\n    xlab = \"Days from Jan 1, 2020\",\n    ylab = \"New Covid Deaths\"\n    )\n  lines(subset(owidall, location == \"Afghanistan\")$new_deaths,\n    lty=\"solid\", col = \"salmon\")\n  legend(x = \"topright\", legend = c(\"Iran\",\"Aghanistan\"), col = c(\"red3\",\"salmon\"),\n         lty = 1\n         )\n\n\n\n\n\n\n3. Bar Chart\n\n## Download COVID data from OWID GitHub\n# Deselect cases/rows with OWID\n## owidall1 = owidall[!grepl(\"^OWID\", owidall$iso_code), ]\nsouth1 = subset(owidall, continent==\"South America\")\n\nstart_date &lt;- as.Date(\"2021-01-01\")\nend_date &lt;- as.Date(\"2021-12-31\")\n\nsouth = subset(south1, date &gt;= start_date & date &lt;= end_date)\nsouth$location &lt;- factor(south$location,levels=rev(unique(south$location)))\n\nbase &lt;- ggplot(south) + geom_col(aes(new_deaths_per_million, location), fill = \"black\", col=\"black\", width = 0.6)\n\nbase + labs(title = \"2021 Covid Deaths in South America\", x = \"Deaths per Million\", y = NULL) + scale_x_continuous(breaks = seq(0, 3000, by = 500)) + theme(\n  panel.background = element_rect(fill = \"white\"),\n  panel.border = element_rect(color = \"black\", linewidth = 1, fill = NA),\n  plot.background = element_rect(fill = \"white\"),\n  panel.grid.major.x = element_line(color = \"red\",\n                                          size = 0.5,\n                                          linetype = 2),\n  plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n4. Column Chart\n\n##owidall1 = owidall[!grepl(\"^OWID\", owidall$iso_code), ]\n# Subset by country: Italy\nitaly = subset(owidall, location==\"Italy\")\n\nstart_date &lt;- as.Date(\"2020-05-01\")\nend_date &lt;- as.Date(\"2020-5-30\")\nitaly = subset(italy, date &gt;= start_date & date &lt;= end_date)\n\nbase &lt;- ggplot(data= (italy), aes(x=as.Date(date))) + \n  geom_bar(aes(y=log(new_cases)), stat=\"identity\", position =\"identity\", alpha=.3, fill='lightblue', color='lightblue3') +\n  geom_bar(aes(y=log(new_deaths)), stat=\"identity\", position=\"identity\", alpha=.8, fill='pink', color='pink3') + xlim(start_date, end_date) + ylim(0,8) + \n  scale_color_manual(values = c(\"New cases\" = \"lightblue\", \"New deaths\" = \"pink\"), name = \"Legend\")\n\nbase + scale_x_date(date_labels = \"%d\", date_break = \"1 day\") + \n  theme(panel.background = element_rect(fill = \"white\"),\n  panel.border = element_rect(color = \"black\", linewidth = 1, fill = NA),\n  plot.background = element_rect(fill = \"white\"),\n  axis.ticks.x=element_blank(), plot.title = element_text(hjust = 0.5),\n  legend.position=\"bottom\") + \n  labs(title = \"Italian Covid Cases vs Deaths in May 2020\", y = \"Frequency\", x = \"Date\", colour = \"Legend\")"
  },
  {
    "objectID": "EPPS6356Assignment5.html",
    "href": "EPPS6356Assignment5.html",
    "title": "EPPS 6356 Assignment 5",
    "section": "",
    "text": "1. R Graphics\n\n#histogram\n\nhist(Orange$circumference, breaks = 20,\n     xlab = \"Circumference\",\n     main = \"The circumference of Orange Trees\",\n     ylab = \"Number of Trees\")\n\n\n\n#Barchart\n##vertical\n\nbarplot(height = ToothGrowth$len, width = ToothGrowth$dose,\n        xlab = \"Dosage\", ylab = \"Tooth Growth\", main = \"The Effect of Suppliments on Guinea Pig Tooth Growth\")\n\n\n\n##horizontal\n\nbarplot(height = ToothGrowth$len, width = ToothGrowth$dose,\n        xlab = \"Tooth Growth\", ylab = \"Dosage\", main = \"The Effect of Suppliments on Guinea Pig Tooth Growth\", horiz = T)\n\n\n\n#Piechart\n\npie(\n  WorldPhones[5,],\n  main = \"Number of Phones in 1959, by continent\"\n)\n\n\n\n#Boxplot\n\nboxplot(attenu$dist ~ attenu$mag,\n        xlab = \"Magnitude\",\n        ylab = \"Distance from epicenter\",\n        main = \"Earthquake measurements\"\n  \n)\n\n\n\n#Scatterplot\n\nplot(iris$Sepal.Length, iris$Sepal.Width,\n     xlab = \"Length\",\n     ylab = \"Width\",\n     main = \"Flower Sepals\"\n\n)\n\n\n\n\n\n\n2. ggplot2\n\n#histogram\n\nggplot(data = Orange, aes(x = Circumfrence) ) +\n  geom_histogram(aes(x = circumference), bins = 20, color=\"black\", fill=\"grey30\") +\n  theme_classic() +\n  labs(title=\"The circumference of Orange Trees\", x = \"Circumference\", y = \"Number of Trees\")\n\n\n\n#Barchart\n##vertical\n\nggplot(data = ToothGrowth, aes(x = len, y = supp, width = dose)) +\n  geom_bar(aes(fill = len), stat=\"identity\", position=\"identity\") +\n  theme_classic() +\n  labs(title=\"Tooth Growth\", x = \"Length\", y = \"Dosage\")\n\n\n\n#Scatterplot\n\nggplot(data = iris) +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width)) +\n  theme_classic() +\n  labs(title=\"Flower Sepals\", x = \"Length\", y = \"Width\")"
  },
  {
    "objectID": "EPPS6356Assignment6.html",
    "href": "EPPS6356Assignment6.html",
    "title": "EPPS 6356 Assignment 6",
    "section": "",
    "text": "https://camronhollis.shinyapps.io/epps6356assignment6/"
  },
  {
    "objectID": "EPPS6356Assignment9.html",
    "href": "EPPS6356Assignment9.html",
    "title": "EPPS 6356 Assignment 9",
    "section": "",
    "text": "1. BBBYQ\nThe stock value of the defunct and dead memestock, BBBYQ. This xts object goes from January 1st 2020, to June 30th, 2023\n\n\n[1] \"BBBYQ\"\n\n\n\n\n\n\n\n2. Variables\nThe xts object has is indexed by time, with each observation being one sequential day. Each observation has the stock ticker open, high, low, and close value.\n\nclass(BBBYQ)\n\n[1] \"xts\" \"zoo\"\n\nsummary(BBBYQ)\n\n     Index              BBBYQ.Open        BBBYQ.High        BBBYQ.Low     \n Min.   :2020-01-02   Min.   : 0.0483   Min.   : 0.1009   Min.   : 0.048  \n 1st Qu.:2020-11-12   1st Qu.: 5.2775   1st Qu.: 5.7175   1st Qu.: 4.985  \n Median :2021-09-29   Median :12.9350   Median :13.7700   Median :12.440  \n Mean   :2021-09-30   Mean   :13.9365   Mean   :14.5584   Mean   :13.390  \n 3rd Qu.:2022-08-15   3rd Qu.:21.7312   3rd Qu.:22.6750   3rd Qu.:21.060  \n Max.   :2023-06-30   Max.   :42.9800   Max.   :53.9000   Max.   :41.117  \n  BBBYQ.Close       BBBYQ.Volume       BBBYQ.Adjusted   \n Min.   : 0.0751   Min.   :  1092694   Min.   : 0.0751  \n 1st Qu.: 5.2975   1st Qu.:  4808161   1st Qu.: 5.2975  \n Median :13.0250   Median :  8098816   Median :13.0250  \n Mean   :13.9094   Mean   : 23515786   Mean   :13.8930  \n 3rd Qu.:21.7925   3rd Qu.: 14734654   3rd Qu.:21.7925  \n Max.   :52.8900   Max.   :962558838   Max.   :52.8900  \n\n\n\n\n3. Analysis\nWe will be using the close value series for the following analysis. Time span is still January 2020 to July 2023.\n\nTrend analysis\nValue and smoothed\n\n\n\n\n\n\n\n\n\n\nStationarity analysis\n\nplot(diff(BBBYQ),\n     lwd = 0.5,\n     main = \"First differences, i.e. daily gain, and month-smoothed value\"\n    )\n\n\n\nlines(diff(rollmean(BBBYQ, 14, align = \"center\") ),\n        col = \"red\"\n    )\n\n\n\n\n\n\npdq & PDQ\nThere may also be some seasonality to the data"
  },
  {
    "objectID": "EPPS6356Assignment10.html#census-api-key",
    "href": "EPPS6356Assignment10.html#census-api-key",
    "title": "EPPS 6356 Assignment 10",
    "section": "2. Census API Key",
    "text": "2. Census API Key\nCensus Key has been received but I won’t be sharing it. :)"
  },
  {
    "objectID": "EPPS6356Assignment10.html#spacialdata-examples",
    "href": "EPPS6356Assignment10.html#spacialdata-examples",
    "title": "EPPS 6356 Assignment 10",
    "section": "3. Spacialdata Examples",
    "text": "3. Spacialdata Examples\n\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\n\nGetting data from the 2019 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n\n\n\n\n\n\n\n\n\nGetting data from the 2016-2020 5-year ACS\n\n\nSimple feature collection with 6896 features and 5 fields (with 12 geometries empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -106.6456 ymin: 25.83738 xmax: -93.50829 ymax: 36.5007\nGeodetic CRS:  NAD83\nFirst 10 features:\n         GEOID                                         NAME   variable estimate\n1  48195950100    Census Tract 9501, Hansford County, Texas B19013_001    53295\n2  48375010700       Census Tract 107, Potter County, Texas B19013_001    47738\n3  48375014100       Census Tract 141, Potter County, Texas B19013_001    38990\n4  48073950801 Census Tract 9508.01, Cherokee County, Texas B19013_001    50117\n5  48085031643    Census Tract 316.43, Collin County, Texas B19013_001    87438\n6  48085032008    Census Tract 320.08, Collin County, Texas B19013_001    84792\n7  48085032012    Census Tract 320.12, Collin County, Texas B19013_001    49429\n8  48085031715    Census Tract 317.15, Collin County, Texas B19013_001   133258\n9  48097000600          Census Tract 6, Cooke County, Texas B19013_001    52335\n10 48097000200          Census Tract 2, Cooke County, Texas B19013_001    83047\n     moe                       geometry\n1  16931 MULTIPOLYGON (((-101.6239 3...\n2  13237 MULTIPOLYGON (((-101.8173 3...\n3   7134 MULTIPOLYGON (((-101.7989 3...\n4  10458 MULTIPOLYGON (((-95.40203 3...\n5  27660 MULTIPOLYGON (((-96.75057 3...\n6  11846 MULTIPOLYGON (((-96.68251 3...\n7   8611 MULTIPOLYGON (((-96.69911 3...\n8  24557 MULTIPOLYGON (((-96.81625 3...\n9  10700 MULTIPOLYGON (((-97.13371 3...\n10 13814 MULTIPOLYGON (((-97.48509 3..."
  },
  {
    "objectID": "EPPS6356Assignment10.html#different-year-comparisons",
    "href": "EPPS6356Assignment10.html#different-year-comparisons",
    "title": "EPPS 6356 Assignment 10",
    "section": "4. Different Year Comparisons",
    "text": "4. Different Year Comparisons\n\n\nGetting data from the 2006-2010 5-year ACS\n\n\nSimple feature collection with 5265 features and 5 fields (with 6 geometries empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -106.6456 ymin: 25.83738 xmax: -93.51641 ymax: 36.5007\nGeodetic CRS:  NAD83\nFirst 10 features:\n         GEOID                                      NAME   variable estimate\n1  48029110100    Census Tract 1101, Bexar County, Texas B19013_001    24922\n2  48029110300    Census Tract 1103, Bexar County, Texas B19013_001    20841\n3  48029110500    Census Tract 1105, Bexar County, Texas B19013_001    11172\n4  48029120300    Census Tract 1203, Bexar County, Texas B19013_001   104668\n5  48029120702 Census Tract 1207.02, Bexar County, Texas B19013_001    70878\n6  48029121108 Census Tract 1211.08, Bexar County, Texas B19013_001    66781\n7  48029121115 Census Tract 1211.15, Bexar County, Texas B19013_001    76625\n8  48029121120 Census Tract 1211.20, Bexar County, Texas B19013_001    57667\n9  48029121205 Census Tract 1212.05, Bexar County, Texas B19013_001    39630\n10 48029121505 Census Tract 1215.05, Bexar County, Texas B19013_001    51334\n     moe                       geometry\n1   3396 MULTIPOLYGON (((-98.49928 2...\n2   4537 MULTIPOLYGON (((-98.48687 2...\n3   4813 MULTIPOLYGON (((-98.51411 2...\n4  13170 MULTIPOLYGON (((-98.45928 2...\n5   8254 MULTIPOLYGON (((-98.48187 2...\n6  10793 MULTIPOLYGON (((-98.47468 2...\n7   7153 MULTIPOLYGON (((-98.46577 2...\n8   4766 MULTIPOLYGON (((-98.43285 2...\n9   4557 MULTIPOLYGON (((-98.4171 29...\n10  5875 MULTIPOLYGON (((-98.33077 2..."
  },
  {
    "objectID": "Presentation2.html",
    "href": "Presentation2.html",
    "title": "Presentation",
    "section": "",
    "text": "summary(\n  lm(data = consolidated_data,\n    Wellbeing ~\n      `Average Life Expectancy` +\n      `Air Pollution - Particulate Matter (Physical Environment)` +\n      `Violent Crime Rate` +\n      `Income Inequality`\n  )\n)\n\n\nCall:\nlm(formula = Wellbeing ~ `Average Life Expectancy` + `Air Pollution - Particulate Matter (Physical Environment)` + \n    `Violent Crime Rate` + `Income Inequality`, data = consolidated_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.0600  -2.8687   0.2616   4.7936  10.7743 \n\nCoefficients:\n                                                              Estimate\n(Intercept)                                                 113.275644\n`Average Life Expectancy`                                    -0.469615\n`Air Pollution - Particulate Matter (Physical Environment)`  -2.014067\n`Violent Crime Rate`                                         -0.001713\n`Income Inequality`                                          -0.229264\n                                                            Std. Error t value\n(Intercept)                                                  33.133613   3.419\n`Average Life Expectancy`                                     0.379396  -1.238\n`Air Pollution - Particulate Matter (Physical Environment)`   0.633859  -3.177\n`Violent Crime Rate`                                          0.008297  -0.206\n`Income Inequality`                                           0.128346  -1.786\n                                                            Pr(&gt;|t|)   \n(Intercept)                                                  0.00381 **\n`Average Life Expectancy`                                    0.23482   \n`Air Pollution - Particulate Matter (Physical Environment)`  0.00625 **\n`Violent Crime Rate`                                         0.83921   \n`Income Inequality`                                          0.09428 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.871 on 15 degrees of freedom\nMultiple R-squared:  0.4559,    Adjusted R-squared:  0.3108 \nF-statistic: 3.142 on 4 and 15 DF,  p-value: 0.04603"
  },
  {
    "objectID": "EPPS6356Assignment8.html",
    "href": "EPPS6356Assignment8.html",
    "title": "EPPS 6356 Assignment 8",
    "section": "",
    "text": "These Shiny Apps will be used for final presentation."
  },
  {
    "objectID": "EPPS6356Assignment8.html#tab-1",
    "href": "EPPS6356Assignment8.html#tab-1",
    "title": "EPPS 6356 Assignment 8",
    "section": "",
    "text": "Content for the first tab goes here."
  },
  {
    "objectID": "EPPS6356Assignment8.html#tab-2",
    "href": "EPPS6356Assignment8.html#tab-2",
    "title": "EPPS 6356 Assignment 8",
    "section": "",
    "text": "Content for the second tab goes here.\n\nTest"
  },
  {
    "objectID": "EPPS6356Assignment8.html#tab-3",
    "href": "EPPS6356Assignment8.html#tab-3",
    "title": "EPPS 6356 Assignment 8",
    "section": "",
    "text": "Content for the third tab goes here."
  },
  {
    "objectID": "EPPS6356Assignment8.html#program-1",
    "href": "EPPS6356Assignment8.html#program-1",
    "title": "EPPS 6356 Assignment 8",
    "section": "",
    "text": "&lt;/section&gt;\n&lt;section id=\"program-2\" class=\"level2\"&gt;\n&lt;h2&gt;Program 2&lt;/h2&gt;\n&lt;iframe id=\"Cities ASL data\" src=\"https://laurencampbell17.shinyapps.io/allcities/\" style=\"border: non; width: 100%; height: 600px\" frameborder=\"no\"&gt;\n\n\nThese Shiny Apps will be used for final presentation."
  },
  {
    "objectID": "EPPS6356Assignment8.html#program-2",
    "href": "EPPS6356Assignment8.html#program-2",
    "title": "EPPS 6356 Assignment 8",
    "section": "",
    "text": "These Shiny Apps will be used for final presentation."
  }
]